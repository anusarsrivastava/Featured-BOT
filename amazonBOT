import csv
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager

#Import ASIN ID of Amazon Product
f = open("C:/Users/anusa/Desktop/my_code_ver_2.0/py_scraper/amazon_scraper/amazon_product_list.txt", 'r+') #for opening file
amazon_product_list = f.read() #for read
amazon_product_list = amazon_product_list.split('\n')

class crawledProduct():
    def __init__(self, title, price):
        self.title = title
        self.price = price
    
class Bot:
    def Product(self, product):
        url = 'https://www.amazon.in/F/dp/' + product

        options = Options()
        options.headless = False
        options.add_experimental_option("detach", True)
        
        browser = webdriver.Chrome(ChromeDriverManager().install(), options=options)
        browser.maximize_window()
        browser.get(url)
        browser.set_page_load_timeout(10)

        
        #Product Title
        xPathTitle = '//*[@id="productTitle"]'
        title = browser.find_element_by_xpath(xPathTitle)
        title = title.get_attribute("innerHTML").splitlines()[1]

        #Product by
        xPathTitle = '//*[@id="bylineInfo"]/span/span[1]/a[1]'
        Product_by = browser.find_element_by_xpath(xPathTitle)
        Product_by = Product_by.get_attribute("innerHTML").splitlines()[0]
        
        #Review
        try:
            xPathTitle = '//*[@id="acrPopover"]/span[1]/a/i[1]'
            Re = browser.find_element_by_xpath(xPathTitle)
            Re = Re.get_attribute("innerHTML").splitlines()[0]
            Re = Re.split('>')
            Re = Re[1].split(' ')
            Review = Re[0]
        except:
            Review = '0'

        #Rating
        try:
            xPathTitle = '/html/body/div[2]/div[2]/div[3]/div[1]/div[5]/div[4]/div/span[3]/a/span'
            Rating = browser.find_element_by_xpath(xPathTitle)
            Rating = Rating.get_attribute("innerHTML").splitlines()[0]
        except:
            Rating = '0'
        #Selling Price
        xPathTitle = '//*[@id="soldByThirdParty"]/span'
        S_P = browser.find_element_by_xpath(xPathTitle)
        S_P = S_P.get_attribute("innerHTML").splitlines()[0]
        S_P = S_P.split('&nbsp;')
        Selling_Price = S_P[0] + " " + S_P[1]

        #MRP Price
        try:
            xPathTitle = '//*[@id="buyBoxInner"]/ul/li[1]/span/span[2]'
            M_P = browser.find_element_by_xpath(xPathTitle)
            M_P = M_P.get_attribute("innerHTML").splitlines()
            M_P = M_P.split('&nbsp;')
            MRP_Price = M_P[0] + " " + M_P[1]
        except:
            MRP_Price = 'N/A'
        
        #Sold by
        xPathTitle = '//*[@id="sellerProfileTriggerId"]'
        Sold_by = browser.find_element_by_xpath(xPathTitle)
        Sold_by = Sold_by.get_attribute("innerHTML").splitlines()[0]
        
        #Page Length
        xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[3]/span/span[2]'
        Page_Length = browser.find_element_by_xpath(xPathTitle)
        Page_Length = Page_Length.get_attribute("innerHTML").splitlines()[0]
        
        #Language
        xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[2]/span/span[2]'
        Language = browser.find_element_by_xpath(xPathTitle)
        Language = Language.get_attribute("innerHTML").splitlines()[0]
        
    #Publisher,Publication date and Edition
        xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[1]/span/span[2]'
        PPE_X = browser.find_element_by_xpath(xPathTitle)
        PPE_X = PPE_X.get_attribute("innerHTML").splitlines()[0]
        PPE1 = PPE_X.split('; ')
        PPE2 = PPE1[1].split(' (')
        PPE3 = PPE2[1].split(')')
        #Publisher
        Publisher = PPE1[0]

        #Publication date
        Publication_date = PPE2[0]
        
        #Edition
        Edition = PPE3[0]

        #Dimensions
        xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[7]/span/span[2]'
        Dimensions = browser.find_element_by_xpath(xPathTitle)
        Dimensions = Dimensions.get_attribute("innerHTML").splitlines()[0]
        
        #ISBN-10
        try:
            xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[4]/span/span[2]'
            ISBN_10 = browser.find_element_by_xpath(xPathTitle)
            ISBN_10 = ISBN_10.get_attribute("innerHTML").splitlines()[0]
        except:
            ISBN_10 = 'N/A'

        #ISBN-13
        try:
            xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[5]/span/span[2]'
            ISBN_13 = browser.find_element_by_xpath(xPathTitle)
            ISBN_13 = ISBN_13.get_attribute("innerHTML").splitlines()[0]
        except:
            ISBN_13 = 'N/A'
        #Item Weight
        xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[6]/span/span[2]'
        Item_Weight = browser.find_element_by_xpath(xPathTitle)
        Item_Weight = Item_Weight.get_attribute("innerHTML").splitlines()[0]
        
        #Country of Origin
        xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[8]/span/span[2]'
        Country_of_Origin = browser.find_element_by_xpath(xPathTitle)
        Country_of_Origin = Country_of_Origin.get_attribute("innerHTML").splitlines()[0]
        
        #Importer
        xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[9]/span/span[2]'
        Importer = browser.find_element_by_xpath(xPathTitle)
        Importer = Importer.get_attribute("innerHTML").splitlines()[0]
        
        #Packer
        xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[10]/span/span[2]'
        Packer = browser.find_element_by_xpath(xPathTitle)
        Packer = Packer.get_attribute("innerHTML").splitlines()[0] 
        
        #Generic Name
        xPathTitle = '//*[@id="detailBullets_feature_div"]/ul/li[11]/span/span[2]'
        Generic_Name = browser.find_element_by_xpath(xPathTitle)
        Generic_Name = Generic_Name.get_attribute("innerHTML").splitlines()[0]
        
        #Best Sellers Rank
        try:
            xPathTitle = '//*[@id="detailBulletsWrapper_feature_div"]/ul[1]/li/span'
            Best_Sellers_Rank = browser.find_element_by_xpath(xPathTitle)
            Best_Sellers_Rank = Best_Sellers_Rank.get_attribute("innerHTML").splitlines()[7]
            Best_Sellers_Rank = Best_Sellers_Rank.split(' (')[0]
        except:
            Best_Sellers_Rank = 'N/A'

        #Category Ranking
        try:
            xPathTitle = '//*[@id="detailBulletsWrapper_feature_div"]/ul[1]/li/span'
            C_R = browser.find_element_by_xpath(xPathTitle)
            C_R = C_R.get_attribute("innerHTML").splitlines()[10]
            C_R = C_R.split('>')
            C_R1 = C_R[2]
            C_R1 = C_R1.strip().split(' <')
            C_R2 = C_R[3]
            C_R2 = C_R2.split('<')
            Category_Ranking = C_R1[0] + " " + C_R2[0]
        except:
            Category_Ranking = 'N/A'

        #Set of Details
        product_details = [product,title,Product_by,Review,Rating,Selling_Price,MRP_Price,Sold_by,Page_Length,Language,Publisher,Publication_date,Edition,Dimensions,ISBN_10,ISBN_13,Item_Weight,Country_of_Origin,Importer,Packer,Generic_Name,Best_Sellers_Rank,Category_Ranking]

        browser.close()

        """for products in product_details:
            print(products)"""
        return product_details

fetcher = Bot()

#Write the product details in CSV
with open('C:/Users/anusa/Desktop/my_code_ver_2.0/py_scraper/amazon_scraper/product_details.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['ASIN','title','Product_by','Review','Rating','Selling_Price','MRP_Price','Sold_by','Page_Length','Language','Publisher','Publication_date','Edition','Dimensions','ISBN_10','ISBN_13','Item_Weight','Country_of_Origin','Importer','Packer','Generic_Name','Best_Sellers_Rank','Category_Ranking'])
    for amazon_product in amazon_product_list:
        writer.writerow(fetcher.Product(amazon_product))
       
